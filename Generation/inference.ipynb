{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DiffyFace - Inference Notebook\n",
        "\n",
        "- Load pretrained LoRA weights\n",
        "- Generate face images from text prompts\n",
        "- Control random seed for reproducibility\n",
        "- Display generated images\n",
        "- Save images to organized folders\n",
        "\n",
        "## Setup\n",
        "Run the cells below to set up the environment and load the model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Install Dependencies\n",
        "\n",
        "Install required packages for inference.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "%pip install -q diffusers==0.27.2 transformers==4.40.1 accelerate==0.29.3 huggingface-hub==0.22.2 peft==0.10.0 safetensors torch torchvision torchaudio pillow\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!git clone https://github.com/rigvedrs/DiffyFace.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Import Libraries and Setup Paths\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import torch\n",
        "from PIL import Image\n",
        "from IPython.display import display\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "# Setup paths - Works for both Colab and local environments\n",
        "def find_project_root():\n",
        "    \"\"\"Find the project root directory.\"\"\"\n",
        "    # Check if we're in Google Colab\n",
        "    try:\n",
        "        import google.colab\n",
        "        IN_COLAB = True\n",
        "    except:\n",
        "        IN_COLAB = False\n",
        "    \n",
        "    if IN_COLAB:\n",
        "        # In Colab, check common locations after git clone\n",
        "        possible_paths = [\n",
        "            Path('/content/DiffyFace'),  \n",
        "            Path('/content/drive/MyDrive/DiffyFace'),  # If cloned to drive\n",
        "            Path.cwd(),  # Current directory\n",
        "        ]\n",
        "        \n",
        "        # Check which path contains the project structure\n",
        "        for path in possible_paths:\n",
        "            if (path / \"Generation\" / \"inference.ipynb\").exists() or \\\n",
        "               (path / \"checkpoints\").exists() or \\\n",
        "               (path / \"README.md\").exists():\n",
        "                return path\n",
        "        \n",
        "        # If not found, use current directory\n",
        "        return Path.cwd()\n",
        "    else:\n",
        "        # Local environment - use current directory or find project root\n",
        "        current = Path.cwd()\n",
        "        # Walk up to find project root (has Generation folder)\n",
        "        for parent in [current] + list(current.parents):\n",
        "            if (parent / \"Generation\").exists() and (parent / \"Training\").exists():\n",
        "                return parent\n",
        "        return current\n",
        "\n",
        "# Find and set project root\n",
        "PROJECT_ROOT = find_project_root()\n",
        "sys.path.insert(0, str(PROJECT_ROOT))\n",
        "\n",
        "# Create output directory for images (Images/colab)\n",
        "OUTPUT_DIR = PROJECT_ROOT / \"Images\" / \"colab\"\n",
        "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(f\"✓ Project root: {PROJECT_ROOT}\")\n",
        "print(f\"✓ Output directory: {OUTPUT_DIR}\")\n",
        "print(f\"✓ PyTorch version: {torch.__version__}\")\n",
        "print(f\"✓ CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"✓ GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    \n",
        "# Verify project structure\n",
        "if (PROJECT_ROOT / \"Generation\").exists():\n",
        "    print(f\"✓ Generation folder found\")\n",
        "if (PROJECT_ROOT / \"checkpoints\").exists():\n",
        "    print(f\"✓ Checkpoints folder found\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from huggingface_hub import hf_hub_download\n",
        "\n",
        "# Check if checkpoints already exist\n",
        "checkpoint_dir = PROJECT_ROOT / \"checkpoints\" / \"lora30k\"\n",
        "checkpoint_file = checkpoint_dir / \"pytorch_lora_weights.safetensors\"\n",
        "USE_LOCAL_MODEL = False  # Set to True if you have the model locally\n",
        "\n",
        "if checkpoint_file.exists():\n",
        "    print(f\"✓ Checkpoints already exist at: {checkpoint_file}\")\n",
        "else:\n",
        "    print(\"Downloading DiffyFace LoRA weights from Hugging Face...\")\n",
        "    checkpoint_dir.mkdir(parents=True, exist_ok=True)\n",
        "    \n",
        "    try:\n",
        "        hf_hub_download(\n",
        "            repo_id=\"rigvedrs/DiffyFace\",\n",
        "            filename=\"pytorch_lora_weights.safetensors\",\n",
        "            local_dir=str(checkpoint_dir),\n",
        "            local_dir_use_symlinks=False\n",
        "        )\n",
        "        print(f\"✓ Successfully downloaded checkpoints to: {checkpoint_dir}\")\n",
        "    except Exception as e:\n",
        "        print(f\"✗ Error downloading checkpoints: {e}\")\n",
        "        print(\"Please download manually or check your internet connection\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**⚠️ Important:** Make sure the checkpoint download cell above completed successfully before proceeding to load the model.\n",
        "\n",
        "The checkpoint file should be at: `checkpoints/lora30k/pytorch_lora_weights.safetensors`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Load the Model\n",
        "\n",
        "Load the Stable Diffusion 2.1 model with LoRA weights. **Requires CUDA/GPU.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from diffusers import StableDiffusionPipeline\n",
        "import torch\n",
        "\n",
        "# Check CUDA availability\n",
        "if not torch.cuda.is_available():\n",
        "    raise RuntimeError(\"CUDA not available! DiffyFace requires a GPU. Please use Google Colab with GPU or a machine with CUDA support.\")\n",
        "\n",
        "device = \"cuda\"\n",
        "print(f\"✓ Using device: {device}\")\n",
        "\n",
        "# Setup paths\n",
        "checkpoint_path = PROJECT_ROOT / \"checkpoints\" / \"lora30k\"\n",
        "weight_name = \"pytorch_lora_weights.safetensors\"\n",
        "\n",
        "# Check for local model\n",
        "local_model_path = PROJECT_ROOT / \"models\" / \"stable-diffusion-2-1\"\n",
        "use_local = False\n",
        "\n",
        "if use_local:\n",
        "    print(f\"✓ Using local model from: {local_model_path}\")\n",
        "    model_path = str(local_model_path)\n",
        "else:\n",
        "    print(\"Using Hugging Face model: rigvedrs/Diffy-2-1\")\n",
        "    model_path = \"rigvedrs/Diffy-2-1\"\n",
        "\n",
        "# Check if checkpoint file exists\n",
        "checkpoint_file = checkpoint_path / weight_name\n",
        "if not checkpoint_file.exists():\n",
        "    raise FileNotFoundError(\n",
        "        f\"LoRA checkpoint file not found at {checkpoint_file}\\n\"\n",
        "        f\"Please run the checkpoint download cell above first, or download manually from:\\n\"\n",
        "        f\"https://huggingface.co/rigvedrs/DiffyFace/tree/main\"\n",
        "    )\n",
        "\n",
        "# Load LoRA state dict\n",
        "print(f\"Loading LoRA weights from {checkpoint_path}...\")\n",
        "try:\n",
        "    state_dict, network_alphas = StableDiffusionPipeline.lora_state_dict(\n",
        "        str(checkpoint_path),\n",
        "        weight_name=weight_name\n",
        "    )\n",
        "    print(\"✓ LoRA weights loaded successfully\")\n",
        "except Exception as e:\n",
        "    raise RuntimeError(f\"Failed to load LoRA weights: {e}\\nMake sure the checkpoint file exists at {checkpoint_path / weight_name}\")\n",
        "\n",
        "# Load the base Stable Diffusion 2.1 model\n",
        "print(f\"Loading Stable Diffusion 2.1 model from {model_path}...\")\n",
        "try:\n",
        "    pipe = StableDiffusionPipeline.from_pretrained(\n",
        "        model_path,\n",
        "        torch_dtype=torch.float16,\n",
        "        local_files_only=use_local  # Use local files only if using local model\n",
        "    ).to(device)\n",
        "    print(\"✓ Base model loaded successfully\")\n",
        "except Exception as e:\n",
        "    error_msg = str(e)\n",
        "    if \"401\" in error_msg or \"Unauthorized\" in error_msg:\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"AUTHENTICATION ERROR\")\n",
        "        print(\"=\"*80)\n",
        "        print(\"If authentication is required, you need to:\")\n",
        "        print(\"1. Get your Hugging Face token from: https://huggingface.co/settings/tokens\")\n",
        "        print(\"2. Set HF_TOKEN environment variable or authenticate in the previous cell\")\n",
        "        print(\"\\nAlternatively, download the model locally:\")\n",
        "        print(\"  python Generation/download_and_upload_model.py --download-only\")\n",
        "        print(\"  Then set USE_LOCAL_MODEL = True in the previous cell\")\n",
        "        print(\"=\"*80)\n",
        "    elif \"not cached locally\" in error_msg.lower():\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"MODEL NOT FOUND\")\n",
        "        print(\"=\"*80)\n",
        "        print(\"The model is not cached locally. Options:\")\n",
        "        print(\"1. Authenticate with Hugging Face (see previous cell)\")\n",
        "        print(\"2. Download the model locally:\")\n",
        "        print(\"   python Generation/download_and_upload_model.py --download-only\")\n",
        "        print(\"   Then set USE_LOCAL_MODEL = True\")\n",
        "        print(\"=\"*80)\n",
        "    raise\n",
        "\n",
        "# Load LoRA weights into model\n",
        "print(\"Loading LoRA weights into model...\")\n",
        "pipe.load_lora_into_unet(\n",
        "    state_dict, network_alphas, pipe.unet, adapter_name='diffyface_lora'\n",
        ")\n",
        "pipe.load_lora_into_text_encoder(\n",
        "    state_dict, network_alphas, pipe.text_encoder, adapter_name='diffyface_lora'\n",
        ")\n",
        "pipe.set_adapters([\"diffyface_lora\"], adapter_weights=[1.0])\n",
        "\n",
        "print(\"✓ Model loaded successfully and ready for inference!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from diffusers import StableDiffusionPipeline\n",
        "import torch\n",
        "\n",
        "# Check CUDA availability\n",
        "if not torch.cuda.is_available():\n",
        "    raise RuntimeError(\"CUDA not available! DiffyFace requires a GPU. Please use Google Colab with GPU or a machine with CUDA support.\")\n",
        "\n",
        "device = \"cuda\"\n",
        "print(f\"✓ Using device: {device}\")\n",
        "\n",
        "# Setup paths\n",
        "checkpoint_path = PROJECT_ROOT / \"checkpoints\" / \"lora30k\"\n",
        "weight_name = \"pytorch_lora_weights.safetensors\"\n",
        "\n",
        "# Load LoRA state dict\n",
        "print(f\"Loading LoRA weights from {checkpoint_path}...\")\n",
        "state_dict, network_alphas = StableDiffusionPipeline.lora_state_dict(\n",
        "    str(checkpoint_path),\n",
        "    weight_name=weight_name\n",
        ")\n",
        "\n",
        "# Load the base Stable Diffusion 2.1 model\n",
        "print(\"Loading Stable Diffusion 2.1 model from rigvedrs/Diffy-2-1...\")\n",
        "pipe = StableDiffusionPipeline.from_pretrained(\n",
        "    \"rigvedrs/Diffy-2-1\",\n",
        "    torch_dtype=torch.float16\n",
        ").to(device)\n",
        "\n",
        "# Load LoRA weights into model\n",
        "pipe.load_lora_into_unet(\n",
        "    state_dict, network_alphas, pipe.unet, adapter_name='diffyface_lora'\n",
        ")\n",
        "pipe.load_lora_into_text_encoder(\n",
        "    state_dict, network_alphas, pipe.text_encoder, adapter_name='diffyface_lora'\n",
        ")\n",
        "pipe.set_adapters([\"diffyface_lora\"], adapter_weights=[1.0])\n",
        "\n",
        "print(\"✓ Model loaded successfully and ready for inference!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Inference Function\n",
        "\n",
        "Function to generate images with customizable parameters.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_face(\n",
        "    prompt: str,\n",
        "    negative_prompt: str = \"\",\n",
        "    num_inference_steps: int = 50,\n",
        "    guidance_scale: float = 7.5,\n",
        "    seed: int = None,\n",
        "    save_image: bool = True,\n",
        "    display_image: bool = True\n",
        "):\n",
        "    \"\"\"\n",
        "    Generate a face image from a text prompt.\n",
        "    \n",
        "    Args:\n",
        "        prompt: Text description of the face to generate\n",
        "        negative_prompt: What to avoid in the generation\n",
        "        num_inference_steps: Number of denoising steps (more = better quality, slower)\n",
        "        guidance_scale: How closely to follow the prompt (higher = more adherence)\n",
        "        seed: Random seed for reproducibility (None = random)\n",
        "        save_image: Whether to save the image to disk\n",
        "        display_image: Whether to display the image in the notebook\n",
        "        \n",
        "    Returns:\n",
        "        Generated PIL Image\n",
        "    \"\"\"\n",
        "    # Set random seed if provided\n",
        "    generator = None\n",
        "    if seed is not None:\n",
        "        generator = torch.manual_seed(seed)\n",
        "        print(f\"Using seed: {seed}\")\n",
        "    \n",
        "    print(f\"Generating image with prompt: '{prompt}'\")\n",
        "    print(f\"Inference steps: {num_inference_steps}, Guidance scale: {guidance_scale}\")\n",
        "    \n",
        "    # Generate image\n",
        "    with torch.no_grad():\n",
        "        result = pipe(\n",
        "            prompt,\n",
        "            negative_prompt=negative_prompt if negative_prompt else None,\n",
        "            num_inference_steps=num_inference_steps,\n",
        "            guidance_scale=guidance_scale,\n",
        "            generator=generator,\n",
        "            cross_attention_kwargs={\"scale\": 1.0} if device == \"cuda\" else None,\n",
        "            output_type=\"pil\"\n",
        "        )\n",
        "    \n",
        "    image = result.images[0]\n",
        "    \n",
        "    # Save image if requested\n",
        "    if save_image:\n",
        "        # Create filename from prompt\n",
        "        filename = prompt.replace(\".\", \" \").replace(\",\", \" \").replace(\"!\", \" \")\n",
        "        filename = \"_\".join(filename.split())\n",
        "        filename = filename.replace(\"__\", \"_\").strip(\"_\")\n",
        "        \n",
        "        # Add timestamp and seed if provided\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        seed_str = f\"_seed{seed}\" if seed is not None else \"\"\n",
        "        filename = f\"{timestamp}_{filename[:50]}{seed_str}.png\"\n",
        "        \n",
        "        # Ensure output directory exists\n",
        "        OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "        \n",
        "        save_path = OUTPUT_DIR / filename\n",
        "        image.save(save_path)\n",
        "        print(f\"✓ Image saved to: {save_path}\")\n",
        "    \n",
        "    # Display image if requested\n",
        "    if display_image:\n",
        "        display(image)\n",
        "    \n",
        "    return image\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================\n",
        "# CONFIGURATION - Modify these values\n",
        "# ============================================\n",
        "\n",
        "# Your prompt describing the face\n",
        "PROMPT = \"A happy 25 year old male with blond hair and a french beard smiles with visible teeth.\"\n",
        "\n",
        "# Negative prompt (what to avoid)\n",
        "NEGATIVE_PROMPT = \"blurry, distorted, low quality, deformed\"\n",
        "\n",
        "# Generation parameters\n",
        "NUM_INFERENCE_STEPS = 50  # More steps = better quality but slower (20-100)\n",
        "GUIDANCE_SCALE = 7.5      # How closely to follow prompt (1.0-20.0)\n",
        "SEED = 42                 # Random seed (None for random, or any integer for reproducibility)\n",
        "\n",
        "# Options\n",
        "SAVE_IMAGE = True         # Save image to disk\n",
        "DISPLAY_IMAGE = True      # Display image in notebook\n",
        "\n",
        "# ============================================\n",
        "# Generate the image\n",
        "# ============================================\n",
        "\n",
        "image = generate_face(\n",
        "    prompt=PROMPT,\n",
        "    negative_prompt=NEGATIVE_PROMPT,\n",
        "    num_inference_steps=NUM_INFERENCE_STEPS,\n",
        "    guidance_scale=GUIDANCE_SCALE,\n",
        "    seed=SEED,\n",
        "    save_image=SAVE_IMAGE,\n",
        "    display_image=DISPLAY_IMAGE\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Batch Generation\n",
        "\n",
        "Generate multiple images with different prompts or seeds.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: Generate multiple images with different seeds\n",
        "prompts = [\n",
        "    \"A happy 25 year old male with blond hair and a french beard smiles with visible teeth.\",\n",
        "    \"A young woman with dark hair and glasses looks serious.\",\n",
        "    \"An elderly man with gray hair and a kind expression.\"\n",
        "]\n",
        "\n",
        "for i, prompt in enumerate(prompts):\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"Generating image {i+1}/{len(prompts)}\")\n",
        "    print(f\"{'='*80}\")\n",
        "    \n",
        "    image = generate_face(\n",
        "        prompt=prompt,\n",
        "        negative_prompt=\"blurry, distorted, low quality\",\n",
        "        num_inference_steps=50,\n",
        "        guidance_scale=7.5,\n",
        "        seed=42 + i,  # Different seed for each image\n",
        "        save_image=True,\n",
        "        display_image=True\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## View Saved Images\n",
        "\n",
        "List and display all saved images.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# List all saved images\n",
        "saved_images = sorted(OUTPUT_DIR.glob(\"*.png\"))\n",
        "print(f\"Total saved images: {len(saved_images)}\")\n",
        "print(f\"\\nSaved images in {OUTPUT_DIR}:\")\n",
        "\n",
        "for img_path in saved_images[-10:]:  # Show last 10 images\n",
        "    print(f\"  - {img_path.name}\")\n",
        "\n",
        "# Display the most recent image\n",
        "if saved_images:\n",
        "    print(f\"\\nMost recent image:\")\n",
        "    latest_image = Image.open(saved_images[-1])\n",
        "    display(latest_image)\n",
        "    print(f\"File: {saved_images[-1].name}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Advanced: Custom Generation\n",
        "\n",
        "For more control, use this cell to experiment with different parameters.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Advanced generation with full control\n",
        "custom_prompt = \"A 30 year old Asian woman with long black hair, wearing glasses, smiling warmly\"\n",
        "custom_negative = \"blurry, distorted, low quality, deformed, ugly\"\n",
        "custom_steps = 75  # Higher quality, slower\n",
        "custom_guidance = 8.0  # Stronger prompt adherence\n",
        "custom_seed = 123  # Set to None for random\n",
        "\n",
        "image = generate_face(\n",
        "    prompt=custom_prompt,\n",
        "    negative_prompt=custom_negative,\n",
        "    num_inference_steps=custom_steps,\n",
        "    guidance_scale=custom_guidance,\n",
        "    seed=custom_seed,\n",
        "    save_image=True,\n",
        "    display_image=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tips for Better Results\n",
        "\n",
        "1. **Detailed Prompts**: Be specific about age, gender, hair, facial features, expression\n",
        "   - Good: \"A happy 25 year old male with blond hair and a french beard smiles with visible teeth.\"\n",
        "   - Bad: \"A person\"\n",
        "\n",
        "2. **Negative Prompts**: Use to avoid unwanted features\n",
        "   - \"blurry, distorted, low quality, deformed, ugly\"\n",
        "\n",
        "3. **Inference Steps**: \n",
        "   - 20-30: Fast, lower quality\n",
        "   - 50: Balanced (recommended)\n",
        "   - 75-100: High quality, slower\n",
        "\n",
        "4. **Guidance Scale**:\n",
        "   - 5.0-7.5: More creative, less strict\n",
        "   - 7.5-10.0: Balanced (recommended)\n",
        "   - 10.0-15.0: Very strict prompt adherence\n",
        "\n",
        "5. **Seed**: Use the same seed to reproduce the same image\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
